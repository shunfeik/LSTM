# -*- coding: utf-8 -*-
"""model.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OY4G0aq550e23BAL2hGbdFX515ihEly_

Design and train the model
"""

import numpy as np
from scipy.integrate import solve_ivp
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import Adam
import matplotlib.pyplot as plt
def rhs(t, z, L1, L2, m1, m2, g=9.81):
    theta1, w1, theta2, w2 = z
    cos12 = np.cos(theta1 - theta2)
    sin12 = np.sin(theta1 - theta2)
    sin1 = np.sin(theta1)
    sin2 = np.sin(theta2)
    xi = cos12**2*m2 - m1 - m2
    w1dot = (L1*m2*cos12*sin12*w1**2 + L2*m2*sin12*w2**2 - m2*g*cos12*sin2 + (m1 + m2)*g*sin1) / (L1*xi)
    w2dot = -(L2*m2*cos12*sin12*w2**2 + L1*(m1 + m2)*sin12*w1**2 + (m1 + m2)*g*sin1*cos12 - (m1 + m2)*g*sin2) / (L2*xi)
    return w1, w1dot, w2, w2dot

def to_cartesian(theta1, w1, theta2, w2, L1, L2):
    x1 = L1 * np.sin(theta1)
    y1 = -L1 * np.cos(theta1)
    x2 = x1 + L2 * np.sin(theta2)
    y2 = y1 - L2 * np.cos(theta2)
    return x1, y1, x2, y2

def generate_data(L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, z0=[np.pi/4, 0, np.pi/4, 0], tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    theta1, w1, theta2, w2 = ret.y
    x1, y1, x2, y2 = to_cartesian(theta1, w1, theta2, w2, L1, L2)
    return np.stack([x1, y1, x2, y2], axis=1), t

data, time = generate_data()

scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

def create_dataset(dataset, look_back=1, steps_ahead=20):
    X, Y = [], []
    for i in range(len(dataset)-look_back-steps_ahead+1):
        a = dataset[i:(i+look_back), :]
        X.append(a)
        Y.append(dataset[i + look_back + steps_ahead - 1, :])
    return np.array(X), np.array(Y)

look_back = 20
steps_ahead = 20
X, Y = create_dataset(data_scaled, look_back, steps_ahead)

model = Sequential()
model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(100, return_sequences=False))
model.add(Dense(data_scaled.shape[1]))

optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')

# Train the model
history = model.fit(X, Y, epochs=200, batch_size=64, validation_split=0.2, verbose=2)

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()



# Use the model to make predictions
predicted_scaled = model.predict(X)

# De-normalize the prediction results
predicted = scaler.inverse_transform(predicted_scaled)

# Select a part of the data for visualization
true_positions = data[look_back + steps_ahead - 1:]
predicted_positions = predicted

# Draw the motion trajectory of m1
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(true_positions[:, 0], true_positions[:, 1], 'r', label='True Path of m1')
plt.plot(predicted_positions[:, 0], predicted_positions[:, 1], 'b--', label='Predicted Path of m1')
plt.title('Future Path of m1')
plt.xlabel('x1')
plt.ylabel('y1')
plt.legend()

# Draw the motion trajectory of m2
plt.subplot(1, 2, 2)
plt.plot(true_positions[:, 2], true_positions[:, 3], 'g', label='True Path of m2')
plt.plot(predicted_positions[:, 2], predicted_positions[:, 3], 'k--', label='Predicted Path of m2')
plt.title('Future Path of m2')
plt.xlabel('x2')
plt.ylabel('y2')
plt.legend()

plt.tight_layout()
plt.show()



"""Make plots of  x  and  y  vs time to show the network prediction in comparison to the solution from solve_ivp"""

# Define three initial conditions
initial_conditions = [
    [np.pi/4, 0, np.pi/4, 0],  #Initial condition 1
    [np.pi/6, 0, np.pi/6, 0],  #Initial condition 2
    [np.pi/3, 0, np.pi/3, 0]  #Initial condition 3
]

datasets = []
times = []

for z0 in initial_conditions:
    data, t = generate_data(z0=z0)
    datasets.append(data)
    times.append(t)

predicted_datasets = []

for data in datasets:
    # Normalising the data
    data_scaled = scaler.fit_transform(data)

    #Create dataset
    X, _ = create_dataset(data_scaled, look_back=20, steps_ahead=20)

    # predict
    predicted_scaled = model.predict(X)
    predicted = scaler.inverse_transform(predicted_scaled)

    predicted_datasets.append(predicted)

# Plot
for i, (data, predicted, t) in enumerate(zip(datasets, predicted_datasets, times)):
    t_pred = t[20:len(predicted)+20]  # Adjust according to look_back and steps_ahead

    plt.figure(figsize=(14, 10))
    plt.suptitle(f'Initial Condition {i+1}')

    # x and y of m1
    plt.subplot(2, 2, 1)
    plt.plot(t, data[:, 0], 'r', label='True x1')
    plt.plot(t_pred, predicted[:, 0], 'b--', label='Predicted x1')
    plt.xlabel('Time')
    plt.ylabel('x1')
    plt.legend()

    plt.subplot(2, 2, 2)
    plt.plot(t, data[:, 1], 'g', label='True y1')
    plt.plot(t_pred, predicted[:, 1], 'k--', label='Predicted y1')
    plt.xlabel('Time')
    plt.ylabel('y1')
    plt.legend()

    # x and y of m2
    plt.subplot(2, 2, 3)
    plt.plot(t, data[:, 2], 'r', label='True x2')
    plt.plot(t_pred, predicted[:, 2], 'b--', label='Predicted x2')
    plt.xlabel('Time')
    plt.ylabel('x2')
    plt.legend()

    plt.subplot(2, 2, 4)
    plt.plot(t, data[:, 3], 'g', label='True y2')
    plt.plot(t_pred, predicted[:, 3], 'k--', label='Predicted y2')
    plt.xlabel('Time')
    plt.ylabel('y2')
    plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

"""Make a plot showing how the deviation between predicted position and actual position (from solve_ivp above) vary as a function of extrapolation time"""

#Specific initial conditions
z0 = [np.pi/4, 0, np.pi/4, 0]
data, t = generate_data(z0=z0)
data_scaled = scaler.fit_transform(data)

# Define Extrapolation time point
steps_aheads = range(20, 101, 20)  # from t=t_0 + 20Δt to t=t_0 + 100Δt

# Initialize error storage: for each Extrapolation time point, we have 4 error values (x1, y1, x2, y2)
errors = np.zeros((len(steps_aheads), 4))  # error array

def evaluate_prediction(model, data, steps_ahead, scaler):
    """Evaluate the prediction error of the model for a given Extrapolation time"""
    #Create dataset
    X, Y_true = create_dataset(data, look_back=20, steps_ahead=steps_ahead)

    # predict
    Y_pred_scaled = model.predict(X)
    Y_pred = scaler.inverse_transform(Y_pred_scaled)

    # Make sure Y_true is the correct shape
    if Y_true.ndim > 2:
        Y_true = Y_true.reshape(Y_true.shape[0], -1)  # Adjust the shape to match the shape of Y_pred

    # Calculation errors
    errors = np.sqrt(np.mean((Y_true - Y_pred) ** 2, axis=0))  # RMSE
    return errors


# Calculate the error at each extended time point
for i, steps_ahead in enumerate(steps_aheads):
    errors[i, :] = evaluate_prediction(model, data_scaled, steps_ahead, scaler)

plt.figure(figsize=(10, 6))

# Plot performance curves
labels = ['x1', 'y1', 'x2', 'y2']
colors = ['red', 'green', 'blue', 'black']

for i in range(4):
    plt.plot(steps_aheads, errors[:, i], label=f'{labels[i]} Error', color=colors[i], marker='o')

plt.title('Model Prediction Error Over Extrapolation Time')
plt.xlabel('Extrapolation Time ($\delta t$)')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

"""Repeat three steps, model construction,  above with different initial conditions $z_0=[\pi/2,0,\pi/2,0]$"""

def rhs(t, z, L1, L2, m1, m2, g=9.81):
    theta1, w1, theta2, w2 = z
    cos12 = np.cos(theta1 - theta2)
    sin12 = np.sin(theta1 - theta2)
    sin1 = np.sin(theta1)
    sin2 = np.sin(theta2)
    xi = cos12**2*m2 - m1 - m2
    w1dot = (L1*m2*cos12*sin12*w1**2 + L2*m2*sin12*w2**2 - m2*g*cos12*sin2 + (m1 + m2)*g*sin1) / (L1*xi)
    w2dot = -(L2*m2*cos12*sin12*w2**2 + L1*(m1 + m2)*sin12*w1**2 + (m1 + m2)*g*sin1*cos12 - (m1 + m2)*g*sin2) / (L2*xi)
    return w1, w1dot, w2, w2dot

def to_cartesian(theta1, w1, theta2, w2, L1, L2):
    x1 = L1 * np.sin(theta1)
    y1 = -L1 * np.cos(theta1)
    x2 = x1 + L2 * np.sin(theta2)
    y2 = y1 - L2 * np.cos(theta2)
    return x1, y1, x2, y2

def generate_data(L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, z0=[np.pi/2, 0, np.pi/2, 0], tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    theta1, w1, theta2, w2 = ret.y
    x1, y1, x2, y2 = to_cartesian(theta1, w1, theta2, w2, L1, L2)
    return np.stack([x1, y1, x2, y2], axis=1), t

data, time = generate_data()

scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

def create_dataset(dataset, look_back=1, steps_ahead=20):
    X, Y = [], []
    for i in range(len(dataset)-look_back-steps_ahead+1):
        a = dataset[i:(i+look_back), :]
        X.append(a)
        Y.append(dataset[i + look_back + steps_ahead - 1, :])
    return np.array(X), np.array(Y)

look_back = 20
steps_ahead = 20
X, Y = create_dataset(data_scaled, look_back, steps_ahead)

model = Sequential()
model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(100, return_sequences=False))
model.add(Dense(data_scaled.shape[1]))

optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')

# Train the model
history = model.fit(X, Y, epochs=200, batch_size=64, validation_split=0.2, verbose=2)

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Use the model to make predictions
predicted_scaled = model.predict(X)

# Denormalized prediction results
predicted = scaler.inverse_transform(predicted_scaled)

# Select a portion of data to visualize
true_positions = data[look_back + steps_ahead - 1:]
predicted_positions = predicted

# Plot the motion trajectory of m1
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(true_positions[:, 0], true_positions[:, 1], 'r', label='True Path of m1')
plt.plot(predicted_positions[:, 0], predicted_positions[:, 1], 'b--', label='Predicted Path of m1')
plt.title('Future Path of m1')
plt.xlabel('x1')
plt.ylabel('y1')
plt.legend()

# Plot the motion trajectory of m2
plt.subplot(1, 2, 2)
plt.plot(true_positions[:, 2], true_positions[:, 3], 'g', label='True Path of m2')
plt.plot(predicted_positions[:, 2], predicted_positions[:, 3], 'k--', label='Predicted Path of m2')
plt.title('Future Path of m2')
plt.xlabel('x2')
plt.ylabel('y2')
plt.legend()

plt.tight_layout()
plt.show()

# Define three initial conditions
initial_conditions = [
    [np.pi/4, 0, np.pi/4, 0],  # Initial conditions 1
    [np.pi/2, 0, np.pi/2, 0],  # Initial conditions 2
    [np.pi/3, 0, np.pi/3, 0]   # Initial conditions 3
]

datasets = []
times = []

for z0 in initial_conditions:
    data, t = generate_data(z0=z0)
    datasets.append(data)
    times.append(t)

predicted_datasets = []

for data in datasets:
    # Normalized
    data_scaled = scaler.fit_transform(data)

    #Create dataset
    X, _ = create_dataset(data_scaled, look_back=20, steps_ahead=20)

    # Predict
    predicted_scaled = model.predict(X)
    predicted = scaler.inverse_transform(predicted_scaled)

    predicted_datasets.append(predicted)

# Plotting
for i, (data, predicted, t) in enumerate(zip(datasets, predicted_datasets, times)):
    t_pred = t[20:len(predicted)+20]  # Adjust according to look_back and steps_ahead

    plt.figure(figsize=(14, 10))
    plt.suptitle(f'Initial Condition {i+1}')

    # x and y of m1
    plt.subplot(2, 2, 1)
    plt.plot(t, data[:, 0], 'r', label='True x1')
    plt.plot(t_pred, predicted[:, 0], 'b--', label='Predicted x1')
    plt.xlabel('Time')
    plt.ylabel('x1')
    plt.legend()

    plt.subplot(2, 2, 2)
    plt.plot(t, data[:, 1], 'g', label='True y1')
    plt.plot(t_pred, predicted[:, 1], 'k--', label='Predicted y1')
    plt.xlabel('Time')
    plt.ylabel('y1')
    plt.legend()

    # x and y of m2
    plt.subplot(2, 2, 3)
    plt.plot(t, data[:, 2], 'r', label='True x2')
    plt.plot(t_pred, predicted[:, 2], 'b--', label='Predicted x2')
    plt.xlabel('Time')
    plt.ylabel('x2')
    plt.legend()

    plt.subplot(2, 2, 4)
    plt.plot(t, data[:, 3], 'g', label='True y2')
    plt.plot(t_pred, predicted[:, 3], 'k--', label='Predicted y2')
    plt.xlabel('Time')
    plt.ylabel('y2')
    plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

#Specific initial conditions
z0 = [np.pi/2, 0, np.pi/2, 0]
data, t = generate_data(z0=z0)
data_scaled = scaler.fit_transform(data)

# Define Extrapolation time point
steps_aheads = range(20, 101, 20)  # from t=t_0 + 20Δt to t=t_0 + 100Δt

# Initialize error storage: for each Extrapolation time point, we have 4 error values (x1, y1, x2, y2)
errors = np.zeros((len(steps_aheads), 4))  # error array

# Calculate the error at each extended time point
for i, steps_ahead in enumerate(steps_aheads):
    errors[i, :] = evaluate_prediction(model, data_scaled, steps_ahead, scaler)

plt.figure(figsize=(10, 6))

# Plot performance curves
labels = ['x1', 'y1', 'x2', 'y2']
colors = ['red', 'green', 'blue', 'black']

for i in range(4):
    plt.plot(steps_aheads, errors[:, i], label=f'{labels[i]} Error', color=colors[i], marker='o')

plt.title('Model Prediction Error Over Extrapolation Time')
plt.xlabel('Extrapolation Time ($\delta t$)')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

"""Repeat the three tasks above, design and train a model, check stability and show prediction limit, with different initial point $z_0=[\pi/2,0,\pi/2,0]$"""

# Use the model to make predictions
predicted_scaled = model.predict(X)

# Denormalized prediction results
predicted = scaler.inverse_transform(predicted_scaled)

# Select a portion of data to visualize
true_positions = data[look_back + steps_ahead - 1:]
predicted_positions = predicted

# Plot the motion trajectory of m1
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(true_positions[:, 0], true_positions[:, 1], 'r', label='True Path of m1')
plt.plot(predicted_positions[:, 0], predicted_positions[:, 1], 'b--', label='Predicted Path of m1')
plt.title('Future Path of m1')
plt.xlabel('x1')
plt.ylabel('y1')
plt.legend()

# Plot the motion trajectory of m2
plt.subplot(1, 2, 2)
plt.plot(true_positions[:, 2], true_positions[:, 3], 'g', label='True Path of m2')
plt.plot(predicted_positions[:, 2], predicted_positions[:, 3], 'k--', label='Predicted Path of m2')
plt.title('Future Path of m2')
plt.xlabel('x2')
plt.ylabel('y2')
plt.legend()

plt.tight_layout()
plt.show()

# Define three initial conditions
initial_conditions = [
    [np.pi/4, 0, np.pi/4, 0],  # Initial conditions 1
    [np.pi/2, 0, np.pi/2, 0],  # Initial conditions 2
    [np.pi/3, 0, np.pi/3, 0]   # Initial conditions 3
]

datasets = []
times = []

for z0 in initial_conditions:
    data, t = generate_data(z0=z0)
    datasets.append(data)
    times.append(t)

predicted_datasets = []

for data in datasets:
    # Normalized
    data_scaled = scaler.fit_transform(data)

    #Create dataset
    X, _ = create_dataset(data_scaled, look_back=20, steps_ahead=20)

    # Predict
    predicted_scaled = model.predict(X)
    predicted = scaler.inverse_transform(predicted_scaled)

    predicted_datasets.append(predicted)

# Plotting
for i, (data, predicted, t) in enumerate(zip(datasets, predicted_datasets, times)):
    t_pred = t[20:len(predicted)+20]  # Adjust according to look_back and steps_ahead

    plt.figure(figsize=(14, 10))
    plt.suptitle(f'Initial Condition {i+1}')

    # x and y of m1
    plt.subplot(2, 2, 1)
    plt.plot(t, data[:, 0], 'r', label='True x1')
    plt.plot(t_pred, predicted[:, 0], 'b--', label='Predicted x1')
    plt.xlabel('Time')
    plt.ylabel('x1')
    plt.legend()

    plt.subplot(2, 2, 2)
    plt.plot(t, data[:, 1], 'g', label='True y1')
    plt.plot(t_pred, predicted[:, 1], 'k--', label='Predicted y1')
    plt.xlabel('Time')
    plt.ylabel('y1')
    plt.legend()

    # x and y of m2
    plt.subplot(2, 2, 3)
    plt.plot(t, data[:, 2], 'r', label='True x2')
    plt.plot(t_pred, predicted[:, 2], 'b--', label='Predicted x2')
    plt.xlabel('Time')
    plt.ylabel('x2')
    plt.legend()

    plt.subplot(2, 2, 4)
    plt.plot(t, data[:, 3], 'g', label='True y2')
    plt.plot(t_pred, predicted[:, 3], 'k--', label='Predicted y2')
    plt.xlabel('Time')
    plt.ylabel('y2')
    plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

def rhs(t, z, L1, L2, m1, m2, g=9.81):
    theta1, w1, theta2, w2 = z
    cos12 = np.cos(theta1 - theta2)
    sin12 = np.sin(theta1 - theta2)
    sin1 = np.sin(theta1)
    sin2 = np.sin(theta2)
    xi = cos12**2*m2 - m1 - m2
    w1dot = (L1*m2*cos12*sin12*w1**2 + L2*m2*sin12*w2**2 - m2*g*cos12*sin2 + (m1 + m2)*g*sin1) / (L1*xi)
    w2dot = -(L2*m2*cos12*sin12*w2**2 + L1*(m1 + m2)*sin12*w1**2 + (m1 + m2)*g*sin1*cos12 - (m1 + m2)*g*sin2) / (L2*xi)
    return w1, w1dot, w2, w2dot

def to_cartesian(theta1, w1, theta2, w2, L1, L2):
    x1 = L1 * np.sin(theta1)
    y1 = -L1 * np.cos(theta1)
    x2 = x1 + L2 * np.sin(theta2)
    y2 = y1 - L2 * np.cos(theta2)
    return x1, y1, x2, y2

def generate_data(L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, z0=[np.pi/2, 0, np.pi/2, 0], tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    theta1, w1, theta2, w2 = ret.y
    x1, y1, x2, y2 = to_cartesian(theta1, w1, theta2, w2, L1, L2)
    return np.stack([x1, y1, x2, y2], axis=1), t

data, time = generate_data()

scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

def create_dataset(dataset, look_back=1, steps_ahead=20):
    X, Y = [], []
    for i in range(len(dataset)-look_back-steps_ahead+1):
        a = dataset[i:(i+look_back), :]
        X.append(a)
        Y.append(dataset[i + look_back + steps_ahead - 1, :])
    return np.array(X), np.array(Y)

look_back = 20
steps_ahead = 20
X, Y = create_dataset(data_scaled, look_back, steps_ahead)

model = Sequential()
model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(100, return_sequences=False))
model.add(Dense(data_scaled.shape[1]))

optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')

# Train the model
history = model.fit(X, Y, epochs=200, batch_size=64, validation_split=0.2, verbose=2)

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

#Specific initial conditions
z0 = [np.pi/2, 0, np.pi/2, 0]
data, t = generate_data(z0=z0)
data_scaled = scaler.fit_transform(data)

# Define Extrapolation time point
steps_aheads = range(20, 101, 20)  # from t=t_0 + 20Δt to t=t_0 + 100Δt

# Initialize error storage: for each Extrapolation time point, we have 4 error values (x1, y1, x2, y2)
errors = np.zeros((len(steps_aheads), 4))  # error array

# Calculate the error at each extended time point
for i, steps_ahead in enumerate(steps_aheads):
    errors[i, :] = evaluate_prediction(model, data_scaled, steps_ahead, scaler)

plt.figure(figsize=(10, 6))

# Plot performance curves
labels = ['x1', 'y1', 'x2', 'y2']
colors = ['red', 'green', 'blue', 'black']

for i in range(4):
    plt.plot(steps_aheads, errors[:, i], label=f'{labels[i]} Error', color=colors[i], marker='o')

plt.title('Model Prediction Error Over Extrapolation Time')
plt.xlabel('Extrapolation Time ($\delta t$)')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

"""Training using only mass $m_2$"""

import numpy as np
from scipy.integrate import solve_ivp
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import Adam
import matplotlib.pyplot as plt

# The original rhs, to_cartesian, generate_data functions remain unchanged

# The modified generate_data function only returns the data of m2
def generate_data_modified(L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, z0=[np.pi/4, 0, np.pi/4, 0], tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    theta1, w1, theta2, w2 = ret.y
    _, _, x2, y2 = to_cartesian(theta1, w1, theta2, w2, L1, L2)
    return np.stack([x2, y2], axis=1), t

# Use the modified function to generate data
data, time = generate_data_modified()

# Data preprocessing, only normalize m2 data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Use the create_dataset function to create a dataset.Doesn't need modification.
X, Y = create_dataset(data_scaled, look_back, steps_ahead)

# Modify the model so that its output layer dimensions match the data of m2
model = Sequential()
model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(100, return_sequences=False))
model.add(Dense(2))  # Only predict the x and y coordinates of m2

# Compile and train the model unchanged
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')
history = model.fit(X, Y, epochs=200, batch_size=64, validation_split=0.2, verbose=2)

# The code for the drawing and prediction parts remains the same, but note that only the predicted trajectory of m2 is drawn.
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()
# Plot the motion trajectory of m2
plt.figure(figsize=(10, 6))
plt.plot(true_positions[:, 2], true_positions[:, 3], 'g', label='True Path of m2')
plt.plot(predicted_positions[:, 2], predicted_positions[:, 3], 'k--', label='Predicted Path of m2')
plt.title('Future Path of m2')
plt.xlabel('x2')
plt.ylabel('y2')
plt.legend()

plt.tight_layout()

# Define three initial conditions
initial_conditions = [
    [np.pi/4, 0, np.pi/4, 0],  # Initial condition 1
    [np.pi/6, 0, np.pi/6, 0],  # Initial condition 1
    [np.pi/3, 0, np.pi/3, 0]   # Initial condition 1
]

datasets = []
times = []

def generate_data_m2_only(z0, L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    _, _, x2, y2 = to_cartesian(*ret.y, L1, L2)
    # Make sure to return an array of (n_samples, 2)
    return np.stack([x2, y2], axis=1), t

data, t = generate_data_m2_only(z0=z0)  # Use specific initial conditions
data_scaled = scaler.fit_transform(data)  # Directly normalize m2 data



for z0 in initial_conditions:
    data, t = generate_data_m2_only(z0=z0)
    datasets.append(data)
    times.append(t)

scaler = MinMaxScaler(feature_range=(0, 1))
predicted_datasets = []

for data in datasets:
    #Normalization is only for m2 data
    data_scaled = scaler.fit_transform(data)

    # Create a data set. Note that X will only contain m2 data.
    X, _ = create_dataset(data_scaled, look_back=20, steps_ahead=20)

    # Predict
    predicted_scaled = model.predict(X)
    predicted = scaler.inverse_transform(predicted_scaled)

    predicted_datasets.append(predicted)

# Plot a chart and only plot the predicted trajectory of m2
for i, (data, predicted, t) in enumerate(zip(datasets, predicted_datasets, times)):
    t_pred = t[20:len(predicted)+20]  # Adjust according to look_back and steps_ahead

    plt.figure(figsize=(12, 6))
    plt.suptitle(f'Initial Condition {i+1} for m2')

    # x and y of m2
    plt.subplot(1, 2, 1)
    plt.plot(t, data[:, 0], 'r', label='True x2')
    plt.plot(t_pred, predicted[:, 0], 'b--', label='Predicted x2')
    plt.xlabel('Time')
    plt.ylabel('x2')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(t, data[:, 1], 'g', label='True y2')
    plt.plot(t_pred, predicted[:, 1], 'k--', label='Predicted y2')
    plt.xlabel('Time')
    plt.ylabel('y2')
    plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

def calculate_prediction_error(X, Y, model, scaler):
    """Calculate the predicted RMSE error"""
    Y_pred_scaled = model.predict(X)
    Y_pred = scaler.inverse_transform(Y_pred_scaled)
    Y_true = scaler.inverse_transform(Y)
    # Calculate RMSE
    rmse = np.sqrt(np.mean((Y_pred - Y_true) ** 2, axis=0))
    return rmse

#Specific initial conditions
z0 = [np.pi/4, 0, np.pi/4, 0]
data_m2, t = generate_data_m2_only(z0=z0)
data_scaled = scaler.fit_transform(data_m2)

# Create a dataset for evaluation
look_back = 20
X, Y = create_dataset(data_scaled, look_back=look_back, steps_ahead=1)  # Notice: This is only for compatibility with the calculate_prediction_error function
# Define different prediction step sizes
steps_aheads = range(20, 101, 20)
errors_x2 = []
errors_y2 = []

for steps_ahead in steps_aheads:
    # Regenerate the data set, changing the prediction step size each time
    X, Y = create_dataset(data_scaled, look_back=look_back, steps_ahead=steps_ahead)
    error = calculate_prediction_error(X, Y, model, scaler)
    errors_x2.append(error[0])  # Error of x2
    errors_y2.append(error[1])  # Error of y2
plt.figure(figsize=(10, 6))
plt.plot(steps_aheads, errors_x2, 'b-o', label='Error x2')
plt.plot(steps_aheads, errors_y2, 'r-s', label='Error y2')
plt.title('Prediction Error vs. Extrapolation Time for m2')
plt.xlabel('Extrapolation Time ($\delta t$)')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
from scipy.integrate import solve_ivp
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import Adam
import matplotlib.pyplot as plt

# The original rhs, to_cartesian, generate_data functions remain unchanged

# The modified generate_data function only returns the data of m2
def generate_data_modified(L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, z0=[np.pi/2, 0, np.pi/2, 0], tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    theta1, w1, theta2, w2 = ret.y
    _, _, x2, y2 = to_cartesian(theta1, w1, theta2, w2, L1, L2)
    return np.stack([x2, y2], axis=1), t

# Use the modified function to generate data
data, time = generate_data_modified()

# Data preprocessing, only normalize m2 data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Use the create_dataset function to create a dataset without modification.
X, Y = create_dataset(data_scaled, look_back, steps_ahead)

# Modify the model so that its output layer dimensions match the data of m2
model = Sequential()
model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(100, return_sequences=False))
model.add(Dense(2))  # Only predict the x and y coordinates of m2

# Compile and train the model unchanged
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')
history = model.fit(X, Y, epochs=200, batch_size=64, validation_split=0.2, verbose=2)

# The code for the drawing and prediction parts remains the same, but note that only the predicted trajectory of m2 is drawn.
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()
# Draw the motion trajectory of m2
plt.figure(figsize=(10, 6))
plt.plot(true_positions[:, 2], true_positions[:, 3], 'g', label='True Path of m2')
plt.plot(predicted_positions[:, 2], predicted_positions[:, 3], 'k--', label='Predicted Path of m2')
plt.title('Future Path of m2')
plt.xlabel('x2')
plt.ylabel('y2')
plt.legend()

plt.tight_layout()

# Define three initial conditions
initial_conditions = [
    [np.pi/4, 0, np.pi/4, 0],  # Initial conditions 1
    [np.pi/6, 0, np.pi/6, 0],  # Initial conditions 2
    [np.pi/2, 0, np.pi/2, 0]   # Initial conditions 3
]

datasets = []
times = []

def generate_data_m2_only(z0, L1=1.0, L2=1.0, m1=3.0, m2=1.0, g=9.81, tmax=50, dt=0.1):
    t = np.arange(0, tmax+dt, dt)
    ret = solve_ivp(rhs, (0, tmax), z0, t_eval=t, args=(L1, L2, m1, m2, g))
    _, _, x2, y2 = to_cartesian(*ret.y, L1, L2)
    # Make sure to return an array of shape (n_samples, 2)
    return np.stack([x2, y2], axis=1), t

data, t = generate_data_m2_only(z0=z0)  # Use specific initial conditions
data_scaled = scaler.fit_transform(data)  # Normalising m2 data



for z0 in initial_conditions:
    data, t = generate_data_m2_only(z0=z0)
    datasets.append(data)
    times.append(t)

scaler = MinMaxScaler(feature_range=(0, 1))
predicted_datasets = []

for data in datasets:
    # Normalization is only for m2 data
    data_scaled = scaler.fit_transform(data)

    # Create a data set. Note that X will only contain m2 data.
    X, _ = create_dataset(data_scaled, look_back=20, steps_ahead=20)

    # predict
    predicted_scaled = model.predict(X)
    predicted = scaler.inverse_transform(predicted_scaled)

    predicted_datasets.append(predicted)

# Draw a chart and only draw the predicted trajectory of m2
for i, (data, predicted, t) in enumerate(zip(datasets, predicted_datasets, times)):
    t_pred = t[20:len(predicted)+20]  # Adjust according to look_back and steps_ahead

    plt.figure(figsize=(12, 6))
    plt.suptitle(f'Initial Condition {i+1} for m2')

    # x and y of m2
    plt.subplot(1, 2, 1)
    plt.plot(t, data[:, 0], 'r', label='True x2')
    plt.plot(t_pred, predicted[:, 0], 'b--', label='Predicted x2')
    plt.xlabel('Time')
    plt.ylabel('x2')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(t, data[:, 1], 'g', label='True y2')
    plt.plot(t_pred, predicted[:, 1], 'k--', label='Predicted y2')
    plt.xlabel('Time')
    plt.ylabel('y2')
    plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

def calculate_prediction_error(X, Y, model, scaler):
    """Calculate the predicted RMSE error"""
    Y_pred_scaled = model.predict(X)
    Y_pred = scaler.inverse_transform(Y_pred_scaled)
    Y_true = scaler.inverse_transform(Y)
    # Calculate RMSE
    rmse = np.sqrt(np.mean((Y_pred - Y_true) ** 2, axis=0))
    return rmse

#Specific initial conditions
z0 = [np.pi/2, 0, np.pi/2, 0]
data_m2, t = generate_data_m2_only(z0=z0)
data_scaled = scaler.fit_transform(data_m2)

# Create a dataset for evaluation
look_back = 20
X, Y = create_dataset(data_scaled, look_back=look_back, steps_ahead=1)  # Notice: This is only for compatibility with the calculate_prediction_error function
# Define different prediction step sizes
steps_aheads = range(20, 101, 20)
errors_x2 = []
errors_y2 = []

for steps_ahead in steps_aheads:
    # Regenerate the data set, changing the prediction step size each time
    X, Y = create_dataset(data_scaled, look_back=look_back, steps_ahead=steps_ahead)
    error = calculate_prediction_error(X, Y, model, scaler)
    errors_x2.append(error[0])  # Error of x2
    errors_y2.append(error[1])  # Error of y2
plt.figure(figsize=(10, 6))
plt.plot(steps_aheads, errors_x2, 'b-o', label='Error x2')
plt.plot(steps_aheads, errors_y2, 'r-s', label='Error y2')
plt.title('Prediction Error vs. Extrapolation Time for m2')
plt.xlabel('Extrapolation Time ($\delta t$)')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()